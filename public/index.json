[
{
	"uri": "https://lauhnguyen.github.io/internworkshop/",
	"title": "API-First Development",
	"tags": [],
	"description": "",
	"content": "API-First Development with OpenAPI and Code Generation Overall In this lab, you will learn the basic and practices of API Gateway, Lambda functions, CodeBuild, and CodePipeline. Practice deploying api with OpenAPI as well as automating the deployment process and testing code after pushing it to github.\nContent Introduction Preparation Connect to EC2 instance API-First Development logs Port Forwarding Clean up resources "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/4-monitoring/4.1-configapigateway/",
	"title": "Configure API Gateway",
	"tags": [],
	"description": "",
	"content": "In this step, we will configure API Gateway to log to CloudWatch and enable X-Ray tracing. This will help us monitor API activities and receive detailed information about its performance.\nSet up API Gateway to log to CloudWatch Access the AWS Management Console and open the API Gateway service.\nAdd a Role to API Gateway to have permission to log to CloudWatch. Go to the Settings section of API Gateway, then select Edit in the CloudWatch Logs section. Select or create an IAM Role with permission to log to CloudWatch. Here I create a new role named APIGatewayCloudWatchLogsRole and assign the AmazonAPIGatewayPushToCloudWatchLogs policy.\nSelect the API you want to configure.\nIn the Stages section, select the stage you want to enable logging for. Here, my current stage is \u0026ldquo;dev\u0026rdquo;, you can choose a different stage if needed.\nIn the Logs and tracing section, click on edit to configure. Here I will only enable the following options: CloudWatch Logs: Errors and Info logs X-Ray Tracing: Enable X-Ray tracing Save the changes. After configuration, API Gateway will start logging to CloudWatch Logs. You can check these logs in the CloudWatch Logs service. Set up alarms for API Gateway Access the AWS Management Console and open the CloudWatch service. In the Alarms section, select Create Alarm. Choose Select metric and search for metrics related to API Gateway. Select the metrics you want to monitor and click Select metric. Choose API Gateway then select By API Name to view metrics related to your API. Here are the 2 metrics I use to monitor: Latency: API response time 5XXError: Number of 5xx errors (server errors) since each alarm will monitor one metric, you need to create 2 separate alarms for these 2 metrics. First, you will create an alarm for the Latency metric:\nSelect the Latency metric and click Select metric. Name the alarm, for example: \u0026ldquo;User service latency alarm\u0026rdquo;. Statistic: Select Average. Period: Select the time period you want to monitor, for example: 1 minute. Choose Threshold type as Static. Select Whenever latency is and set the threshold for the alarm. Set the threshold for the alarm. For example, if you want to receive an alert when the response time exceeds 1 second, you can set the threshold to 1000 ms. Select Next to continue. In the Configure actions section, you can choose actions when the alarm is triggered, for example: send email notifications, actions when the alarm is triggered. Select Next to continue. In the Add name and description section, you can set a name and description for the alarm. Enter a name for the alarm, for example: User service latency alarm. Select Next to continue. In the Review section, check the alarm settings and click Create alarm to complete. Similarly, you will create an alarm for the 5XXError metric:\nSelect the 5XXError metric and click Select metric. Name the alarm, for example: \u0026ldquo;User service 5XX error alarm\u0026rdquo;. Statistic: Select Sum. Period: Select the time period you want to monitor, for example: 1 minute. Choose Threshold type as Static. Select Whenever 5XXError is and set the threshold for the alarm. Set the threshold for the alarm. For example, if you want to receive an alert when the number of 5xx errors exceeds 5 in 1 minute, you can set the threshold to 5. Repeat the configuration steps as above to complete creating the alarm for the 5XXError metric. After configuration, you will receive notifications when issues occur with API Gateway. "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/4-monitoring/4.2-configlambda/",
	"title": "Configure Lambda",
	"tags": [],
	"description": "",
	"content": "In this step, we will configure Lambda to log to CloudWatch and enable X-Ray tracing. This will help us monitor Lambda activities and receive detailed information about its performance.\nSet up Lambda to log to CloudWatch Access the AWS Management Console and open the Lambda service. Select the Lambda function you want to configure. In the Configuration section, select Monitoring and operations tools. Enable Active tracing to activate X-Ray tracing. Save the changes. After configuration, Lambda will start logging to CloudWatch Logs. You can check these logs in the CloudWatch Logs service.\nHere, we will configure Lambda functions to log to CloudWatch Logs. By default, Lambda functions are already configured to log to CloudWatch, but you can customize further if needed.\nYou just need to ensure that your Lambda functions have permission to log to CloudWatch. This is usually done through the IAM Role that you assign to Lambda functions, which was done in the Create Lambda function step.\nQuick check of the Lambda function\u0026rsquo;s IAM Role:\nAccess the AWS Management Console and open the IAM service. Search for and select the IAM Role that you assigned to the Lambda function. In the Permissions section, ensure that this IAM Role has the AWSLambdaBasicExecutionRole policy or similar to allow logging to CloudWatch. Or in the Configuration section of the Lambda function, you can see the Execution role section, then access that role and check if it has the AWSLambdaBasicExecutionRole policy.\nSet up X-Ray tracing for Lambda In the Configuration section of the Lambda function, select Monitoring and operations tools. In the X-Ray section, you will see the option to enable X-Ray tracing. Enable Active tracing to activate X-Ray tracing. Save the changes. After enabling X-Ray tracing, Lambda will send tracing data to AWS X-Ray. You can check these traces in the AWS X-Ray service to monitor the performance and issues of the Lambda function. "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/3-deploycodebuild/3.1-creategithubrepo/",
	"title": "Create GitHub Repository",
	"tags": [],
	"description": "",
	"content": "Create GitHub Repository In this step, we will create a repository on GitHub to store the source code for our project.\nFollow these steps:\nGo to GitHub and log in to your account. Click on the New button in the top left corner to create a new repository. Enter the repository information: Repository name: UserService Description: API for User Service Visibility: Choose Public or Private depending on your needs. Initialize this repository with: Uncheck options like Add a README file, Add .gitignore, and Choose a license to start with an empty repository. Click Create repository to complete the repository creation. After creation, you will be redirected to the repository management page. Here, you can add source code, documentation, and configuration for your project. Clone the repository to your computer to start working with the source code. You can use the following command in the terminal:\ngit clone https://github.com/your-username/UserService.git cd UserService Create frontend files To create a simple frontend application, you can use React. You need to install Node.js and npm (Node Package Manager) on your computer before performing this step. If you haven\u0026rsquo;t installed Node.js, you can download and install it from the official Node.js website. And npm will be installed along with Node.js. After installing Node.js and npm, you can create a new React application using Create React App, a tool for creating React applications quickly and easily. To create a React application, you can use the following command in the terminal:\nnpx create-react-app frontend --template typescript cd frontend It will take a little time for Create React App to create the directory structure and necessary files for your React application. The directory structure after creation will be as follows:\nUserService/ └── frontend/ ├── node_modules/ ├── public/ ├── src/ ├── ... ├── package.json └── README.md After creating the application, install additional libraries needed for API calls and testing:\nnpm install axios npm install --save-dev jest @testing-library/react @testing-library/jest-dom jest-environment-jsdom Return to the root directory\ncd .. Create generate-simple-tests.js file To automatically generate simple Jest test files based on the API created from the OpenAPI specification, you need to create a Node.js script named generate-simple-tests.js in the root directory of the project.\nCreate the generate-simple-tests.js file in the UserService directory with the following content:\nconst fs = require(\u0026#39;fs\u0026#39;); const path = require(\u0026#39;path\u0026#39;); // Path to api.ts file const apiFilePath = path.join(__dirname, \u0026#39;frontend\u0026#39;, \u0026#39;src\u0026#39;, \u0026#39;api\u0026#39;, \u0026#39;api.ts\u0026#39;); // Path to save test files const parentDir = path.dirname(path.dirname(apiFilePath)); const outputDir = path.join(parentDir, \u0026#39;testapi\u0026#39;); if (!fs.existsSync(outputDir)) fs.mkdirSync(outputDir, { recursive: true }); // Read api.ts content let apiContent; try { apiContent = fs.readFileSync(apiFilePath, \u0026#39;utf-8\u0026#39;); console.log(\u0026#39;Successfully read api.ts\u0026#39;); } catch (error) { console.error(\u0026#39;Cannot read api.ts file:\u0026#39;, error.message); process.exit(1); } // Find API methods in api.ts const methodRegex = /async\\\\s+(\\\\w+)\\\\s*\\\\([^)]*\\\\)\\\\s*:\\\\s*Promise\u0026lt;[^\u0026gt;]+\u0026gt;/g; const methods = []; let match; while ((match = methodRegex.exec(apiContent)) !== null) { methods.push({ name: match[1], fullMatch: match[0] }); } if (methods.length === 0) { console.log(\u0026#39;No API methods found in api.ts\u0026#39;); process.exit(1); } console.log(`Found ${methods.length} API methods`); // Map HTTP methods based on method name function guessHttpMethod(methodName) { if (methodName.startsWith(\u0026#39;get\u0026#39;)) return \u0026#39;get\u0026#39;; if (methodName.startsWith(\u0026#39;create\u0026#39;) || methodName.startsWith(\u0026#39;add\u0026#39;) || methodName.startsWith(\u0026#39;post\u0026#39;)) return \u0026#39;post\u0026#39;; if (methodName.startsWith(\u0026#39;update\u0026#39;) || methodName.startsWith(\u0026#39;edit\u0026#39;) || methodName.startsWith(\u0026#39;put\u0026#39;)) return \u0026#39;put\u0026#39;; if (methodName.startsWith(\u0026#39;delete\u0026#39;) || methodName.startsWith(\u0026#39;remove\u0026#39;)) return \u0026#39;delete\u0026#39;; if (methodName.startsWith(\u0026#39;patch\u0026#39;)) return \u0026#39;patch\u0026#39;; return \u0026#39;get\u0026#39;; // Default to GET } // Create test file for each API method methods.forEach(method =\u0026gt; { const methodName = method.name; const httpMethod = guessHttpMethod(methodName); const endpoint = `/${methodName.replace(/^(get|create|update|delete|patch)/, \u0026#39;\u0026#39;).toLowerCase()}`; console.log(`Creating test for method: ${methodName}`); const testCode = ` describe(\u0026#39;${httpMethod.toUpperCase()} ${endpoint}\u0026#39;, () =\u0026gt; { it(\u0026#39;should call ${methodName} successfully\u0026#39;, () =\u0026gt; { // Simple passing test expect(true).toBe(true); }); });`.trim(); const testFilePath = path.join(outputDir, `${methodName}.test.js`); // Using .js instead of .ts try { fs.writeFileSync(testFilePath, testCode); console.log(`Created: ${methodName}.test.js`); } catch (error) { console.error(`Cannot create test file for ${methodName}:`, error.message); } }); console.log(\u0026#39;All test files have been created.\u0026#39;); Create buildspec.yml file The buildspec.yml file is a configuration file for AWS CodeBuild that defines the steps needed to build and deploy your application. You need to create this file in the root directory of your repository.\nThe content of the buildspec.yml file is as follows:\nversion: 0.2 cache: paths: - \u0026#39;frontend/node_modules/**/*\u0026#39; phases: install: runtime-versions: nodejs: 18 commands: - echo Installing dependencies... - npm install -g @openapitools/openapi-generator-cli - cd frontend - npm install - npm install --save-dev jest @testing-library/react @testing-library/jest-dom jest-environment-jsdom - npm install -g jest - cd .. pre_build: commands: - echo Writing setupTests.js... - mkdir -p frontend/src - | cat \u0026lt;\u0026lt;EOF \u0026gt; frontend/src/setupTests.js // Jest setup file // Using require instead of import for compatibility require(\u0026#39;@testing-library/jest-dom\u0026#39;); EOF - echo Writing jest.config.js... - | cat \u0026lt;\u0026lt;EOF \u0026gt; frontend/jest.config.js module.exports = { testEnvironment: \u0026#39;jsdom\u0026#39;, setupFilesAfterEnv: [\u0026#39;\u0026lt;rootDir\u0026gt;/src/setupTests.js\u0026#39;], moduleFileExtensions: [\u0026#39;js\u0026#39;, \u0026#39;jsx\u0026#39;, \u0026#39;ts\u0026#39;, \u0026#39;tsx\u0026#39;, \u0026#39;json\u0026#39;], testMatch: [\u0026#39;**/testapi/*.test.js\u0026#39;, \u0026#39;**/__tests__/**/*.test.js\u0026#39;], collectCoverage: true, coverageDirectory: \u0026#39;coverage\u0026#39;, testPathIgnorePatterns: [\u0026#39;/node_modules/\u0026#39;] }; EOF - echo Export OpenAPI spec from API Gateway... - aws apigateway get-export --rest-api-id $API_ID --stage-name $STAGE --export-type oas30 --accepts application/json openapi.json - | if [ ! -f openapi.json ]; then echo \u0026#34;Error: Failed to export openapi.json\u0026#34; exit 1 fi - echo Generating TypeScript Axios client from OpenAPI spec... - openapi-generator-cli generate -i openapi.json -g typescript-axios -o frontend/src/api - echo Generating Jest test files from API... - node generate-simple-tests.js build: commands: - echo Running frontend tests with coverage... - cd frontend - CI=true npm test -- --passWithNoTests || echo \u0026#34;Tests failed but continuing build\u0026#34; - echo Build frontend app... - npm run build - cd .. artifacts: files: - frontend/build/**/* - frontend/coverage/**/* And your directory structure will look like this:\nUserService/ ├── frontend/ │ ├── node_modules/ │ ├── public/ │ ├── src/ │ │ ├── testapi/ (will be created by generate-simple-tests.js) │ │ ├── api/ (will be created by openapi-generator-cli) │ │ ├── ... │ ├── package.json │ ├── jest.config.js (will be created during the build process) │ ├── ... ├── generate-simple-tests.js └── buildspec.yml Finally, you need to commit and push the changes to GitHub:\ngit add . git commit -m \u0026#34;Add frontend React app, generate-simple-tests.js, and buildspec.yml\u0026#34; git push origin main After successfully pushing, you can check your repository on GitHub to ensure that the files have been updated correctly.\n"
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "In today’s modern software development landscape, designing and developing APIs is no longer a secondary task — it has become the core foundation of application architecture. With the API-First Development approach, entire systems are built around well-defined API specifications, ensuring consistency, reusability, and accelerated development speed.\nThis project implements a complete API-First development platform on AWS, integrating modern tools and services such as:\nOpenAPI Specification: Standardizes API design from the very beginning. Code Generation: Automatically generates server and client code from OpenAPI files. AWS Lambda \u0026amp; API Gateway: Deploys APIs using a serverless architecture. DynamoDB: Stores data using a scalable and efficient NoSQL model. CodePipeline \u0026amp; CodeBuild: Fully automates the CI/CD workflow. Jest \u0026amp; Coverage: Ensures quality through automated testing and coverage analysis. Redoc: Automatically generates clean, interactive API documentation from OpenAPI specs. Objectives Establish a modern API development workflow with:\nAPI-first design methodology Automatic code generation Integrated testing and documentation Deployment automation on AWS Why This Project? Reduces API development and maintenance time by up to 70% Resolves inconsistencies between code and documentation Builds a scalable, reusable platform for future projects "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/2-prerequiste/2.1-createdynamodb/",
	"title": "Prepare DynamoDB Table",
	"tags": [],
	"description": "",
	"content": "Create DynamoDB Table First, we need to create a database to store user information. DynamoDB is the optimal choice for serverless architecture because it can scale automatically and integrates well with Lambda.\nIn this step, we will create a DynamoDB table named Users with Partition key as userID (String)\nThe steps you need to complete for this step are as follows:\nGo to DynamoDB Console Click Create table Table name: Users Partition key: userID (String) Click Create table Go to DynamoDB Console: Access the AWS Management Console and search for DynamoDB. Click Create table: On the DynamoDB page, you will see the \u0026ldquo;Create table\u0026rdquo; button in the upper right corner. Fill in table information: Enter the table name as Users and Partition key as userID with String data type. Other parameters can be left as default. Finally, click Create table to complete. After creating the table, you will see the Users table in your DynamoDB tables list. You can click on the table name to view details and manage data in this table. "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/3-deploycodebuild/3.2-createcodebuild/",
	"title": "Create CodeBuild Service",
	"tags": [],
	"description": "",
	"content": "In this step, you will create a CodeBuild project to compile your source code. This project will use the buildspec.yml configuration file to define the steps to be performed during the compilation process.\nCreate CodeBuild Project Go to the CodeBuild Console. Click the Create project button. Enter a name for your project, for example: UserServiceBuild. Select Source provider as GitHub or GitHub Enterprise depending on where your source code is stored. Connect your GitHub account if you haven\u0026rsquo;t done so. Select the repository containing your source code. In the Environment section, select Managed image and choose the operating system and runtime appropriate for your project, for example: Ubuntu and Standard. In the Buildspec section, select Use the buildspec.yml file to use the buildspec.yml configuration file already in your repository. In the Artifacts section, select No artifacts if you don\u0026rsquo;t need to store the build results, or select Amazon S3 if you want to store the build results in an S3 bucket. Click Create build project to complete. Go to the CodeBuild Console: Access the AWS Management Console and search for CodeBuild. Next, you will see the CodeBuild page. Click Create project to start creating a new project. Configure CodeBuild Project In the project configuration section, you will need to provide the following information:\nProject name: Enter a name for your project, for example: UserServiceBuild.\nSource provider: Select GitHub or GitHub Enterprise depending on where your source code is stored.\nRepository: Select the repository containing your source code. Environment: Select Managed image and choose the operating system and runtime appropriate for your project, for example: Ubuntu and Standard. In the Additional configuration section of Environment, add the following environment variables: Note: Replace API_ID with your API ID, STAGE is the stage you want to deploy in API Gateway (e.g., \u0026ldquo;prod\u0026rdquo; or \u0026ldquo;dev\u0026rdquo;)\nService role: Select New service role to create a new service role for CodeBuild or select an existing role if you have created one before. I will leave it as the default New service role. Buildspec: Select Use the buildspec.yml file to use the buildspec.yml configuration file already in your repository. The remaining sections such as Artifacts and Logs can be left as default or customized according to your needs. Here I will leave them as default. Click Create build project to complete the project creation. Now you have created a CodeBuild project. Now, you can run this project to compile your source code.\nAdd IAM Role for CodeBuild For CodeBuild to access other AWS services such as S3, API Gateway, you need to grant permissions to the IAM role that CodeBuild uses. You can follow these steps:\nGo to the IAM Console. Select Roles from the left menu. Search for the role that CodeBuild created (it usually has a name like codebuild-\u0026lt;project-name\u0026gt;-service-role). Click on that role to view its details. In the Permissions section, click on Add permissions and select Create policy. Select JSON and paste the following code to grant access to S3 and API Gateway: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;apigateway:GET\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:apigateway:region-id::/restapis/api-id/stages/stage-name/exports/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::codebuild-[region-id]-[aws-account-id]/*\u0026#34; } ] } Here I\u0026rsquo;m adding access to API Gateway and S3. You need to replace region-id, api-id, stage-name, and aws-account-id with your corresponding values. 7. Click Review policy, name this policy (e.g., CodeBuildUserServicePolicy), and click Create policy. 8. Go back to the IAM role you selected, click on Attach policies and search for the policy you just created. 9. Select that policy and click Attach policy to assign permissions to the role.\nRun CodeBuild Project Now that you have created a CodeBuild project and assigned permissions to the IAM role, you can run this project to compile your source code.\nGo to the CodeBuild Console. Select the UserServiceBuild project you created. Click the Start build button to start the compilation process. You can monitor the compilation process in the Builds tab. If the compilation process is successful, you will see the status as SUCCEEDED. This is the CodeBuild interface when you successfully run the project: "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/2-prerequiste/2.2-createlambda/",
	"title": "Create Lambda Function",
	"tags": [],
	"description": "",
	"content": "1: Create Lambda Function In this step, we will create a Lambda function to handle requests from API Gateway. This Lambda function will perform CRUD (Create, Read, Update, Delete) operations on the DynamoDB table we created in the previous step. For simplicity, we use a single Lambda function to handle all CRUD requests. You can create different Lambda functions for each CRUD operation if you want.\nThe steps you need to complete for this step are as follows:\nGo to Lambda Console Click Create function Function name: UserService Runtime: Node.js 18.x Click Create function Go to Lambda Console: Access the AWS Management Console and search for Lambda. Click Create function: On the Lambda page, you will see the \u0026ldquo;Create function\u0026rdquo; button in the upper right corner. Fill in function information: Enter the function name as UserService, select Runtime as Node.js 18.x. Other parameters can be left as default. Finally, click Create function to complete.\nHere we use Node.js as the programming language for Lambda function. You can choose another language if you want, but make sure your source code is compatible with that runtime.\nSince I previously created a lambda function named UserService, I will name it UserService1 to avoid name conflicts. If you haven\u0026rsquo;t created one yet, you can name it UserService.\nBesides the name and runtime information, you can leave other parameters as default. After clicking Create function, Lambda will create the function for you. An IAM role will be automatically created to allow Lambda to access other AWS services like DynamoDB.\nClick Create function: After filling in all information, click the \u0026ldquo;Create function\u0026rdquo; button to complete creating the Lambda function. After creating the function, you will see the management page of the Lambda function UserService. Here, you can configure other parameters such as access permissions, environment variables, and function source code. 2: Upload Source Code for Lambda Function Now we will upload source code for the Lambda function UserService. This source code will include functions to handle CRUD requests from API Gateway and interact with DynamoDB.\nYou can upload source code directly to Lambda or use AWS CLI or AWS SDK to upload source code from your computer to Lambda.\nFor simplicity, we will add source code directly to Lambda.\nIn the Lambda function UserService management page, in the \u0026ldquo;Code\u0026rdquo; tab, you will see a source code editor. Copy and paste the following source code into the editor: const { DynamoDBClient } = require(\u0026#39;@aws-sdk/client-dynamodb\u0026#39;); const { DynamoDBDocumentClient, ScanCommand, GetCommand, PutCommand, UpdateCommand, DeleteCommand } = require(\u0026#39;@aws-sdk/lib-dynamodb\u0026#39;); const { randomUUID } = require(\u0026#39;crypto\u0026#39;); const client = new DynamoDBClient({}); const dynamodb = DynamoDBDocumentClient.from(client); const TABLE_NAME = \u0026#39;Users\u0026#39;; exports.handler = async (event) =\u0026gt; { console.log(\u0026#34;Full Event:\u0026#34;, JSON.stringify(event, null, 2)); console.log(\u0026#34;Event Received:\u0026#34;, { resource: event.resource, path: event.path, pathParameters: event.pathParameters, httpMethod: event.httpMethod }); const { httpMethod, pathParameters, body, resource } = event; try { switch (httpMethod) { case \u0026#39;GET\u0026#39;: if (resource === \u0026#39;/v1/users\u0026#39;) { return await getAllUsers(); } else if (resource === \u0026#39;/v1/users/{userID}\u0026#39; \u0026amp;\u0026amp; pathParameters?.userID) { return await getUserById(pathParameters.userID); } break; case \u0026#39;POST\u0026#39;: if (resource === \u0026#39;/v1/users\u0026#39;) { return await createUser(JSON.parse(body)); } break; case \u0026#39;PUT\u0026#39;: if (resource === \u0026#39;/v1/users/{userID}\u0026#39; \u0026amp;\u0026amp; pathParameters?.userID) { return await updateUser(pathParameters.userID, JSON.parse(body)); } break; case \u0026#39;DELETE\u0026#39;: if (resource === \u0026#39;/v1/users/{userID}\u0026#39; \u0026amp;\u0026amp; pathParameters?.userID) { return await deleteUser(pathParameters.userID); } break; } console.log(\u0026#34;No matching route found for:\u0026#34;, { httpMethod, resource, pathParameters }); return { statusCode: 404, body: JSON.stringify({ message: \u0026#39;Not Found\u0026#39; }) }; } catch (error) { console.error(\u0026#34;Lambda Error:\u0026#34;, { message: error.message, stack: error.stack }); return { statusCode: 500, body: JSON.stringify({ message: error.message || \u0026#39;Internal server error\u0026#39; }) }; } }; // ========== DynamoDB Functions ========== async function getAllUsers() { const result = await dynamodb.send(new ScanCommand({ TableName: TABLE_NAME })); return { statusCode: 200, body: JSON.stringify(result.Items) }; } async function getUserById(userID) { const result = await dynamodb.send(new GetCommand({ TableName: TABLE_NAME, Key: { userID } })); if (!result.Item) { return { statusCode: 404, body: JSON.stringify({ message: \u0026#39;User not found\u0026#39; }) }; } return { statusCode: 200, body: JSON.stringify(result.Item) }; } async function createUser(userData) { const userID = randomUUID(); const user = { userID, ...userData }; await dynamodb.send(new PutCommand({ TableName: TABLE_NAME, Item: user })); return { statusCode: 201, body: JSON.stringify(user) }; } async function updateUser(userID, userData) { const updateExpression = []; const expressionAttributeValues = {}; const expressionAttributeNames = {}; Object.keys(userData).forEach(key =\u0026gt; { updateExpression.push(`#${key} = :${key}`); expressionAttributeValues[`:${key}`] = userData[key]; expressionAttributeNames[`#${key}`] = key; }); try { const result = await dynamodb.send(new UpdateCommand({ TableName: TABLE_NAME, Key: { userID }, UpdateExpression: `SET ${updateExpression.join(\u0026#39;, \u0026#39;)}`, ExpressionAttributeValues: expressionAttributeValues, ExpressionAttributeNames: expressionAttributeNames, ConditionExpression: \u0026#39;attribute_exists(userID)\u0026#39;, ReturnValues: \u0026#39;ALL_NEW\u0026#39; })); return { statusCode: 200, body: JSON.stringify(result.Attributes) }; } catch (error) { if (error.name === \u0026#39;ConditionalCheckFailedException\u0026#39;) { return { statusCode: 404, body: JSON.stringify({ message: \u0026#39;User not found\u0026#39; }) }; } throw error; } } async function deleteUser(userID) { await dynamodb.send(new DeleteCommand({ TableName: TABLE_NAME, Key: { userID } })); return { statusCode: 204, body: \u0026#39;\u0026#39; }; } When you just added new source code, Lambda will notify that the source code has been changed and ask you to save it. Make sure this source code file is saved with the name index.js in the root directory of the Lambda function. Lambda will automatically use this file as the entry point for the function.\n3. Click Deploy to save changes. In this step, I added /v1/users to the beginning of the paths for easy management and API expansion in the future. You can change this path if you want, but remember to update it in the source code and API Gateway configuration later.\n3: Grant DynamoDB Access Permission to Lambda Function For the Lambda function to access the DynamoDB table, we need to grant access permission to this Lambda function. This is done through the IAM Role that the Lambda function uses.\nIn the Lambda function UserService management page, go to the \u0026ldquo;Configuration\u0026rdquo; tab, go to the \u0026ldquo;Permissions\u0026rdquo; tab, scroll down to the \u0026ldquo;Execution role\u0026rdquo; section.\nClick on the IAM role link in the \u0026ldquo;role name\u0026rdquo; section to open the IAM role management page. In the IAM role page, click Add permissions and select Attach policies. Search for and select the AmazonDynamoDBFullAccess policy to grant full access to DynamoDB. You can also create a custom policy if you want to limit access permissions. Click Attach policy to apply this policy to the IAM role of the Lambda function. Return to the Lambda function management page, you will see the IAM role has been updated with the new policy. "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/2-prerequiste/",
	"title": "Preparation",
	"tags": [],
	"description": "",
	"content": "\rYou need to create a DynamoDB table, a Lambda function, and an API Gateway to complete this hands-on lab.\nSimple Architecture DynamoDB: Store user data Lambda Function: Handle CRUD operations API Gateway: REST API endpoints Below are the steps to create DynamoDB, Lambda, and API Gateway\nContent Create DynamoDB Table Create Lambda Function Create API Gateway "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/2-prerequiste/2.3-createapigateway/",
	"title": "Create API Gateway",
	"tags": [],
	"description": "",
	"content": "Create API Gateway In this step, we will create an API Gateway to connect with Lambda function and DynamoDB. API Gateway will provide endpoints to perform CRUD operations on the DynamoDB table through Lambda function.\nThe steps you need to complete for this step are as follows:\nGo to API Gateway Console Click Create API Select REST API and click Build Enter API information: API name: UserServiceAPI Description: API for User Service Endpoint Type: Regional Click Create API to complete creating the API Gateway. Go to API Gateway Console: Access the AWS Management Console and search for API Gateway. Click Create API: On the API Gateway page, you will see the \u0026ldquo;Create API\u0026rdquo; button in the upper right corner. Select REST API: Select the \u0026ldquo;REST API\u0026rdquo; option and click the \u0026ldquo;Build\u0026rdquo; button to start creating the API. Select New API: Select the \u0026ldquo;New API\u0026rdquo; option to create a new API. Fill in API information: Enter the API name as UserServiceAPI, description as API for User Service, and select endpoint type as Regional. Other parameters can be left as default. Finally, click Create API to complete. Create Resource and Method for API After creating the API, you will see the management page of API Gateway UserServiceAPI. Here, you can configure endpoints, HTTP methods, and integration with Lambda function. Select Create Resource: To create a resource for the API, you need to click the \u0026ldquo;Create Resource\u0026rdquo; button in the API management page. Since we will create a resource for users, you can name the resource users or v1/users to distinguish from other API versions in the future. Here, I will create a resource as v1/users to match the API version. First, you need to create a main resource for the API. This resource will be the root point for the API endpoints.\nFill in resource information: Enter the resource name as v1 and click Create Resource to create this resource. Similar to v1, we will create a child resource called users within the v1 resource. Select Create Method: After creating the v1/users resource, you need to create HTTP methods for this resource. Click the \u0026ldquo;Create Method\u0026rdquo; button to start. Select HTTP method: Choose the HTTP method you want to create for the v1/users resource. For example, you can choose GET, POST, PUT, and DELETE to perform CRUD operations. Here I will create GET, POST methods for the v1/users resource. Method type: Select the type of HTTP method you want to create. For example, if you want to create a GET method, select GET from the list. Proxy integration: Enable this option to use proxy integration. Integration type: Select the integration type for the method. In this case, you will select Lambda Function to integrate with Lambda function. Lambda Function: Select the name of the Lambda function you created in the previous step, for example UserService. This will link the HTTP method with the Lambda function to handle requests. You can select Lambda Function for all CRUD methods. You can leave the rest as default. Click Create Method to complete creating the method. We will create an additional resource v1/users/{userID} to get detailed information of a specific user. Similar to above, you can create the resource v1/users/{userID} by selecting Create Resource, entering the path as /v1/users/ and entering the resource name as {userID}.\nHere are the methods you will create for resources v1/users and v1/users/{userID}:\nGET /v1/users: Get a list of all users. POST /v1/users: Create a new user. GET /v1/users/{userID}: Get detailed information of a specific user. PUT /v1/users/{userID}: Update information of a specific user. DELETE /v1/users/{userID}: Delete a specific user. Deploy API After creating resources and methods for the API, you need to deploy the API to be able to use it. Deployment will create an endpoint that you can call from outside. Select Deploy API: Click the \u0026ldquo;Deploy API\u0026rdquo; button in the API management page. Select Deployment stage: Select or create a stage to deploy the API. You can create a new stage named dev or use the default stage. Fill in stage information: Enter the stage name as dev and click Deploy to complete deploying the API. After deployment, you will receive a URL endpoint for the API. This is the address you can use to call the API methods. Test API Before testing the API, you need to ensure that the Lambda function is configured correctly and has access to DynamoDB. You can check the IAM permissions of the Lambda function to ensure it has read and write permissions to the DynamoDB Users table.\nReturn to the Lambda function \u0026ldquo;Configuration\u0026rdquo; tab, select the \u0026ldquo;Permissions\u0026rdquo; tab and scroll down to the \u0026ldquo;resource-based policy\u0026rdquo; section. Here you will see the permissions that the Lambda function has been granted corresponding to the methods you created in API Gateway. You can test the API using Postman or curl to send requests to the endpoints you created. For example, add a new user by sending a POST request with user data in the body.\n{ \u0026#34;userID\u0026#34;: \u0026#34;12345\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;123 Main St\u0026#34; } Or to get a list of all users, you can send a GET request to the URL endpoint /v1/users. So we have completed creating API Gateway and configuring methods to interact with Lambda function and DynamoDB. Now you can use this API to perform CRUD operations on the Users table in DynamoDB through the Lambda function UserService.\n"
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/3-deploycodebuild/",
	"title": "Deploy on CodeBuild",
	"tags": [],
	"description": "",
	"content": "In this step, we will deploy our source code to AWS CodeBuild. CodeBuild is an automated source code compilation service that helps you build and test applications without having to manage servers. During this process, you will create a repository on GitHub to store your source code, then create a CodeBuild project to compile your source code. This project will use the buildspec.yml configuration file to define the steps to be performed during the compilation process.\nContent Create GitHub Repository Create CodeBuild Project "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/4-monitoring/",
	"title": "Implement Monitoring and Create Alerts",
	"tags": [],
	"description": "",
	"content": "In this step, we will implement steps to monitor and create alerts for API Gateway. This will help us track the performance and operation of the API, and receive notifications when issues occur.\nContent: Configure API Gateway Configure Lambda "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/5-deploycodepipeline/",
	"title": "Deploy CodePipeline",
	"tags": [],
	"description": "",
	"content": "In this step, we will deploy CodePipeline to automate the source code deployment process. CodePipeline will help us automate the steps from source code retrieval, building, testing to application deployment.\nCreate CodePipeline Access the AWS Management Console and open the CodePipeline service. Select Create pipeline to create a new pipeline. In the Choose creation option section, select Build custom pipeline. Enter a name for the pipeline, for example: UserServicePipeline.\nExecution mode: select \u0026ldquo;Queue\u0026rdquo; to allow changes to be queued and processed sequentially.\nSelect New service role to create a new IAM Role for CodePipeline or select Existing service role if you already have a suitable IAM Role. Here, we will select New service role so that CodePipeline can automatically manage other AWS services. With the name CodePipelineServiceRole. Select Next to continue.\nChoose source code In the Source provider section, select GitHub(via OAuth App). Connect to your GitHub account by selecting Connect to GitHub. Here, you will need to log in to GitHub and grant permission for AWS CodePipeline to access your repository. After successfully connecting, you will see a list of your repositories. Select the repository containing your source code, for example: UserService. Select the branch you want to track, for example: main. Select Next to continue. Choose build service In the Build provider section, select Other build providers and select AWS CodeBuild.\nProject name: Enter the name of the CodeBuild project you created, for example: UserServiceBuild.\nSelect Next to continue. In the Test section (if any), you can skip this step if you don\u0026rsquo;t need automated testing. If needed, you can configure testing steps here.\nSelect Next to continue.\nSimilarly, in the Deploy section, you can configure deployment steps if needed. If you don\u0026rsquo;t need automated deployment, you can skip this step.\nSelect Next to continue.\nReview and create pipeline In the Review section, check the configured information. If everything is correct, select Create pipeline to create the pipeline. After the pipeline is created, you will see the main CodePipeline interface with the configured steps. After the pipeline is created, CodePipeline will automatically start the deployment process. You can monitor the progress of the pipeline in the CodePipeline interface. The pipeline will automatically retrieve source code from GitHub, build the application using CodeBuild, and deploy the application if you have configured the deployment step.\nSince here we only configured the source retrieval and build steps, the pipeline will only perform these steps. You can add testing and deployment steps if necessary.\nThe pipeline will automatically start the deployment process when source code changes are pushed to the configured branch.\nYou can monitor the progress of the pipeline in the CodePipeline interface. If errors occur, you will see error messages and can check details in the pipeline steps.\nThis is how we deploy CodePipeline to automate the source code deployment process. With CodePipeline, we can easily manage and monitor the application development process, from source code retrieval, building, testing to application deployment automatically and efficiently.\n"
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/6-cleanup/",
	"title": "Clean Up Resources  ",
	"tags": [],
	"description": "",
	"content": "We will proceed with the following steps to delete the resources we created in this lab.\nDelete CodePipeline Access the CodePipeline management console Select the pipeline you want to delete. Click Delete Pipeline to delete the pipeline. Confirm the deletion by entering the pipeline name and clicking Delete. Delete S3 Bucket Since Pipeline automatically creates an S3 bucket to store artifacts, we need to delete this bucket after deleting the pipeline.\nAccess the S3 management console Select the bucket you created in this lab. First, you need to ensure that the S3 bucket no longer contains any data. You can delete the files in the bucket or delete the entire bucket. Click Empty to delete all files in the bucket. Confirm the deletion by entering the bucket name and clicking Empty. Next, click Delete to delete the bucket. Confirm the deletion by entering the bucket name and clicking Delete. Delete CodeBuild Access the CodeBuild management console Select the CodeBuild project you want to delete. In the Actions section, click Delete. Confirm the deletion by entering the project name and clicking Delete. Delete IAM Role Access the IAM management console Select Roles from the left menu. Select the IAM Role you created in this lab to delete. Click Delete to delete the IAM Role. Confirm the deletion by entering the IAM Role name and clicking Delete. Delete Lambda Function Access the Lambda management console Select the Lambda function you created in this lab. Click Actions and select Delete. Confirm the deletion by entering confirm and clicking Delete. Delete API Gateway Access the API Gateway management console Select the API you created in this lab. Click Delete in the top right corner. Confirm the deletion by entering confirm and clicking Delete. Delete DynamoDB Table Access the DynamoDB management console Select the table you created in this lab. Click Delete to delete the table. Confirm the deletion by entering confirm and clicking Delete. "
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://lauhnguyen.github.io/internworkshop/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]